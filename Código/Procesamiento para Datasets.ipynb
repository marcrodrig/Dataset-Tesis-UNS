{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "source": [
    "# Recopilación de datos de Twitter para usuarios legítimos\n",
    "## Se utiliza el módulo Tweepy, se necesita: Consumer_KEY, Consumer_secret_KEY, Access_token, Access_Token_Secret"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key  = 'd9Ksoz6Wb1jD0mqbW8rjaSNb7'\n",
    "consumer_secret = 'pHXnVSJeLbOxaYlbOR7BWFdDNhZSF6IzegZV87qUSUqy6Qe8qG'\n",
    "access_token = '3648603434-dGRu1nHet22tdoYeqaAGoN8MyZrNw9oXZQvGZUD'\n",
    "access_token_secret = 'PZ8pcQBCb5zVPLRQNVQZc3Yzi0rz1wPef6O7RO7gzcvOf'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "source": [
    "## Para usuarios genuinos, colecto una lista de 2500 usuarios seguidos por screen_name=@verified, esos usuarios están verificados y se guardan en un archivo .txt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de usuarios seguidos por @verified')\n",
    "friends = []\n",
    "for friend in tweepy.Cursor(api.friends, screen_name = 'verified').items(2500):\n",
    "    try:\n",
    "        friends.append(friend.screen_name)\n",
    "        print(friend.screen_name)\n",
    "        time.sleep()\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "with open(\"Data/Reales/verified-2500.txt\", \"w\") as f:\n",
    "     for item in friends:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "source": [
    "## Recopilo 30 tweets de cada usuario verificado extraído de Twitter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "listaTweetsUsuariosLegitimos = []\n",
    "fo = open(\"../Data/Reales/verified-2500.txt\", \"r\")\n",
    "f = fo.readlines()\n",
    "fo.close()\n",
    "dataset = map(lambda s: s.strip(),f)\n",
    "counter = 0\n",
    "try:\n",
    "    for user in dataset:\n",
    "        counter = counter + 1\n",
    "        print(f'[{counter}] Obteniendo a lo sumo 30 tweets de {user}. ', end = '\\n')\n",
    "        try:\n",
    "            for status in tweepy.Cursor(api.user_timeline, id = user, tweet_mode=\"extended\").items(30):\n",
    "                listaTweetsUsuariosLegitimos.append(status)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "except Exception as e:\n",
    "    pass\n",
    "print(len(listaTweetsUsuariosLegitimos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "def process_http(string):\n",
    "    url_count = 0\n",
    "    for i in string.split():\n",
    "        s, n, p, pa, q, f = urllib.parse.urlparse(i)\n",
    "        if s and n:\n",
    "            url_count += 1\n",
    "    return url_count\n",
    "\n",
    "def process_hashtag(string):\n",
    "    hashtag_count = 0\n",
    "    for i in string.split():\n",
    "        s, n, p, pa, q, f = urllib.parse.urlparse(i)\n",
    "        if i[:1] == '#':\n",
    "            hashtag_count += 1\n",
    "    return hashtag_count\n",
    "\n",
    "def process_mention(string):\n",
    "    mention_count=0\n",
    "    for i in string.split():\n",
    "        s, n, p, pa, q, f = urllib.parse.urlparse(i)\n",
    "        if i[:1] == '@':\n",
    "            mention_count += 1\n",
    "    return mention_count\n",
    "\n",
    "def process_data(listaTweets):\n",
    "    TweetID = [tweet.id for tweet in listaTweets]\n",
    "\n",
    "    Data = pd.DataFrame(TweetID, columns = ['TweetID'])\n",
    "    \n",
    "    Data[\"TextData\"] = [tweet.full_text for tweet in listaTweets]\n",
    "    Data[\"TweetCreatedAt\"] = [tweet.created_at for tweet in listaTweets]\n",
    "    Data[\"RetweetCount\"] = [tweet.retweet_count for tweet in listaTweets]\n",
    "    Data[\"TweetFavouriteCount\"] = [tweet.favorite_count for tweet in listaTweets]\n",
    "    Data[\"TweetSource\"] = [tweet.source for tweet in listaTweets]\n",
    "    \n",
    "    Data[\"UserID\"] = [tweet.author.id for tweet in listaTweets]\n",
    "    Data[\"UserScreenName\"] = [tweet.author.screen_name for tweet in listaTweets]\n",
    "    Data[\"UserName\"] = [tweet.author.name for tweet in listaTweets]\n",
    "    Data[\"UserCreatedAt\"] = [tweet.author.created_at for tweet in listaTweets]\n",
    "    Data[\"UserDescription\"] = [tweet.author.description for tweet in listaTweets]\n",
    "    Data[\"UserDescriptionLength\"] = [len(tweet.author.description) for tweet in listaTweets]\n",
    "    Data[\"UserFollowersCount\"] = [tweet.author.followers_count for tweet in listaTweets]\n",
    "    Data[\"UserFriendsCount\"] = [tweet.author.friends_count for tweet in listaTweets]\n",
    "    Data[\"UserLocation\"] = [tweet.author.location for tweet in listaTweets]\n",
    "    \n",
    "    Data[\"HttpCount\"] = [process_http(tweet.full_text) for tweet in listaTweets]\n",
    "    Data[\"HashtagCount\"] = [process_hashtag(tweet.full_text) for tweet in listaTweets]\n",
    "    Data[\"MentionCount\"] = [process_mention(tweet.full_text) for tweet in listaTweets]\n",
    "    Data[\"TweetCount\"] = [tweet.author.statuses_count for tweet in listaTweets]\n",
    "    return Data"
   ]
  },
  {
   "source": [
    "## De cada tweet, se extraen atributos útiles que se necesitan después para la clasificación"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = process_data(listaTweetsUsuariosLegitimos)\n",
    "Data.shape"
   ]
  },
  {
   "source": [
    "## Se guardan los datos en un archivo .csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "Data.to_csv('../Data/Reales/Reales_data.csv', sep=',' , encoding='utf8', index=False)"
   ]
  },
  {
   "source": [
    "## Para usuarios bots, colecto algunos usuarios de una lista proveída en botwiki-2019 obtenida en https://botometer.iuni.iu.edu/bot-repository/datasets.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "tsv_file = open(\"../Data/Bots/botwiki-2019.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "counter = 0\n",
    "bots = []\n",
    "for row in read_tsv:\n",
    "    counter = counter + 1\n",
    "    idBot = row[0]\n",
    "    try:\n",
    "        user = api.get_user(idBot)\n",
    "        print(f'[{counter}] {user.screen_name}.', end = '\\n')\n",
    "        bots.append(user.screen_name)\n",
    "    except tweepy.TweepError as e:\n",
    "        counter = counter - 1\n",
    "        mensajeError = e.args[0][0]['message']\n",
    "        print(f'{idBot}: {mensajeError}', end = '\\n')\n",
    "        pass\n",
    "tsv_file.close()\n",
    "with open(\"../Data/Bots/botwiki-2019.txt\", \"w\") as f:\n",
    "     for item in bots:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "source": [
    "## Recopilo 40 tweets de cada usuario bot extraído de botwiki-2019.tsv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "listaTweetsBots = []\n",
    "fo = open(\"../Data/Bots/botwiki-2019.txt\", \"r\")\n",
    "f = fo.readlines()\n",
    "fo.close()\n",
    "dataset = map(lambda s: s.strip(),f)\n",
    "counter = 0\n",
    "try:\n",
    "    for user in dataset:\n",
    "        counter = counter + 1\n",
    "        print(f'[{counter}] Obteniendo al menos 40 tweets de {user}. ', end = '\\n')\n",
    "        try:\n",
    "            for status in tweepy.Cursor(api.user_timeline, id = user, tweet_mode=\"extended\").items(40):\n",
    "                listaTweetsBots.append(status)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "except Exception as e:\n",
    "    pass\n",
    "print(len(listaTweetsBots))"
   ]
  },
  {
   "source": [
    "## De cada tweet, se extraen atributos útiles que se necesitan después para la clasificación"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = process_data(listaTweetsBots)\n",
    "Data.shape"
   ]
  },
  {
   "source": [
    "## Se guardan los datos en un archivo .csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Saving data with item space separating\n",
    "Data.to_csv('../Data/Bots/Bots_data.csv', sep=',' , encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo los datos de los usuarios legítimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_leg_data = pd.read_csv('../Data/Reales/Reales_data.csv')\n",
    "Total_leg_data.fillna(0, inplace=True)\n",
    "Total_leg_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo los datos de los usuarios bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_bot_data = pd.read_csv(\"../Data/Bots/Bots_data.csv\")\n",
    "#Fill NAN values to 0\n",
    "Total_bot_data.fillna(0, inplace=True)\n",
    "Total_bot_data.shape"
   ]
  },
  {
   "source": [
    "## Gráfico de barras que visualiza la ubicación proveniente de los tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_data = Total_leg_data['UserLocation'].value_counts()\n",
    "location_data[2:15].plot(kind='bar', figsize=(14,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_data = Total_bot_data['UserLocation'].value_counts()\n",
    "location_data[2:15].plot(kind='bar', figsize=(14,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrego diferentes características al dataset al calcular:\n",
    "\n",
    "# 1. AvgHashtag\n",
    "# 2. AvgURLCount\n",
    "# 3. AvgMention\n",
    "# 4. AvgRetweet\n",
    "# 5. AvgFavCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_leg_data.loc[:,\"AvgHashtag\"] = (Total_leg_data.groupby('UserID')[\"HashtagCount\"].transform('sum'))/30\n",
    "Total_leg_data.loc[:,\"AvgURLCount\"] = (Total_leg_data.groupby('UserID')[\"HttpCount\"].transform('sum'))/30\n",
    "Total_leg_data.loc[:,\"AvgMention\"] = (Total_leg_data.groupby('UserID')[\"MentionCount\"].transform('sum'))/30\n",
    "Total_leg_data.loc[:,\"AvgRetweet\"] = (Total_leg_data.groupby('UserID')[\"RetweetCount\"].transform('sum'))/30\n",
    "Total_leg_data.loc[:,\"AvgFavCount\"] = (Total_leg_data.groupby('UserID')[\"TweetFavouriteCount\"].transform('sum'))/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_bot_data.loc[:,'AvgHashtag'] = (Total_bot_data.groupby('UserID')[\"HashtagCount\"].transform('sum'))/40\n",
    "Total_bot_data.loc[:,'AvgURLCount'] = (Total_bot_data.groupby('UserID')[\"HttpCount\"].transform('sum'))/40\n",
    "Total_bot_data.loc[:,'AvgMention'] = (Total_bot_data.groupby('UserID')[\"MentionCount\"].transform('sum'))/40\n",
    "Total_bot_data.loc[:,'AvgRetweet'] = (Total_bot_data.groupby('UserID')[\"RetweetCount\"].transform('sum'))/40\n",
    "Total_bot_data.loc[:,'AvgFavCount'] = (Total_bot_data.groupby('UserID')[\"TweetFavouriteCount\"].transform('sum'))/40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecciono solo columnas repetidas y elimino las filas repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_leg_row = Total_leg_data[[\"UserID\", \"UserScreenName\", \"UserName\", \"UserCreatedAt\", \"UserDescription\", \"UserDescriptionLength\",\"UserFollowersCount\", \"UserFriendsCount\", \"UserLocation\", \"AvgHashtag\", \"AvgURLCount\", \"AvgMention\", \"AvgRetweet\", \"AvgFavCount\", \"TweetCount\"]]\n",
    "leg_data = unique_leg_row.drop_duplicates()\n",
    "leg_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_spam_row = Total_bot_data[[\"UserID\", \"UserScreenName\", \"UserName\", \"UserCreatedAt\", \"UserDescription\", \"UserDescriptionLength\",\"UserFollowersCount\", \"UserFriendsCount\", \"UserLocation\", \"AvgHashtag\", \"AvgURLCount\", \"AvgMention\", \"AvgRetweet\", \"AvgFavCount\", \"TweetCount\"]]\n",
    "bot_data = unique_spam_row.drop_duplicates()\n",
    "bot_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "CurrentDate = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d')\n",
    "leg_data.loc[:, \"CurrentDate\"] = CurrentDate\n",
    "leg_data.loc[:, \"bot\"] = 0\n",
    "leg_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentDate = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d')\n",
    "bot_data.loc[:, \"CurrentDate\"] = CurrentDate\n",
    "bot_data.loc[:, \"bot\"] = 1\n",
    "bot_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusiono los datos de los usuarios legítimos y bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [leg_data, bot_data]\n",
    "Total_data = pd.concat(frames, axis=0, sort=False)\n",
    "Total_data.info()"
   ]
  },
  {
   "source": [
    "## Se guardan los datos en un archivo .csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_data.reset_index()\n",
    "Total_data.to_csv('../Data/Dataset.csv', sep=',', encoding='utf8', index = False)"
   ]
  },
  {
   "source": [
    "# Cargo los datos totales (legítimos y bots)\n",
    "# Desde acá comenzará el aprendizaje automatizado (machine learning), prueba con un clasificador Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_data = pd.read_csv('../Data/Dataset.csv')\n",
    "Total_data.fillna(0, inplace=True)\n",
    "Total_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrego la característica Reputación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_data.loc[:,\"Reputation\"]=Total_data[\"AvgRetweet\"]/(Total_data[\"UserFollowersCount\"])\n",
    "Total_data[\"Reputation\"].describe()"
   ]
  },
  {
   "source": [
    "## Agrego la característica AgeOfAccount"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Total_data\n",
    "data[\"CurrentDate\"] = pd.to_datetime(data[\"CurrentDate\"])\n",
    "data[\"UserCreatedAt\"] = pd.to_datetime(data[\"UserCreatedAt\"])\n",
    "data['AgeOfAccount'] = (data['CurrentDate'] - data['UserCreatedAt'])/np.timedelta64(1, 'D')\n",
    "cols = ['AgeOfAccount']\n",
    "data[cols] = data[cols].mask(data[cols]<0)\n",
    "data.AgeOfAccount.describe()"
   ]
  },
  {
   "source": [
    "## Agrego característica tweet por día"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data\n",
    "data1.loc[:, \"TweetPerDay\"] = data1[\"TweetCount\"]/data1[\"AgeOfAccount\"]\n",
    "data1[\"TweetPerDay\"].describe()"
   ]
  },
  {
   "source": [
    "## Agrego característica tweet por seguidor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[:,\"TweetPerFollower\"] = data1[\"TweetCount\"]/data1[\"UserFollowersCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove unwanted data\n",
    "data1.TweetPerFollower=data1.TweetPerFollower.round(2).fillna(0)\n",
    "data1 = data1[np.isfinite(data1['TweetPerFollower'])]\n",
    "data1[\"TweetPerFollower\"].tail(3)"
   ]
  },
  {
   "source": [
    "## Agrego la característica Age of Account/Número de seguidos\n",
    "## Hipótesis: es muy bajo para spammers/bots y muy alto para usuarios legítimos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[:,\"AgeByFollowing\"] = data1[\"AgeOfAccount\"]/data1[\"UserFriendsCount\"]\n",
    "data1 = data1[np.isfinite(data1['AgeByFollowing'])]\n",
    "data1[['AgeByFollowing']] = data1[['AgeByFollowing']].astype(float)\n",
    "data1[\"AgeByFollowing\"].describe()"
   ]
  },
  {
   "source": [
    "## Agrego características que indican si screen_name, name o description contienen alguna palabra relacionada a bot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[:,'screen_name_binary'] = (data1.UserScreenName.str.contains(\"Bot|bot|b0t|B0t|BOT\", case=False)==True)\n",
    "data1['name_binary'] = (data1.UserName.str.contains(\"Bot|bot|b0t|B0t|BOT\", case=False)==True)\n",
    "data1['description_binary'] = (data1.UserDescription.str.contains(\"Bot|bot|b0t|B0t|BOT\", case=False)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[['screen_name_binary']] = data1[['screen_name_binary']].astype(int)\n",
    "data1[['name_binary']] = data1[['name_binary']].astype(int)\n",
    "data1[['description_binary']] = data1[['description_binary']].astype(int)\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecciono las características para la predicción y el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1[['Reputation', 'AvgHashtag', 'AvgRetweet', 'UserFollowersCount','UserFriendsCount', 'AvgFavCount', 'AvgMention', 'AvgURLCount', 'TweetCount', 'AgeOfAccount', 'TweetPerDay', 'TweetPerFollower', 'AgeByFollowing', 'screen_name_binary', 'name_binary', 'description_binary']]\n",
    "y = data1[\"bot\"]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemento el clasificador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=7, max_depth=7, min_samples_split=5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "print(\"Trainig Accuracy: %.5f\" %accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy: %.5f\" %accuracy_score(y_test, y_pred_test))\n",
    "print(\"Classifier performance report: \")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "scores_train = rf.predict_proba(X_train)\n",
    "scores_test = rf.predict_proba(X_test)\n",
    "\n",
    "y_scores_train = []\n",
    "y_scores_test = []\n",
    "for i in range(len(scores_train)):\n",
    "    y_scores_train.append(scores_train[i][1])\n",
    "\n",
    "for i in range(len(scores_test)):\n",
    "    y_scores_test.append(scores_test[i][1])\n",
    "    \n",
    "fpr_rf_train, tpr_rf_train, _ = roc_curve(y_train, y_scores_train, pos_label=1)\n",
    "fpr_rf_test, tpr_rf_test, _ = roc_curve(y_test, y_scores_test, pos_label=1)\n",
    "fig=plt.figure(figsize=(8, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot(fpr_rf_train, tpr_rf_train, color='darkblue', label='Train AUC: %5f' %auc(fpr_rf_train, tpr_rf_train))\n",
    "plt.plot(fpr_rf_test, tpr_rf_test, color='red', ls='--', label='Test AUC: %5f' %auc(fpr_rf_test, tpr_rf_test))\n",
    "plt.title(\"Random ForestROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "source": [
    "# Prueba de predicción"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_Data = []\n",
    "#user = 'afa' // resultado 0\n",
    "user = 'RecuerdameBot'\n",
    "counter = 0\n",
    "try:\n",
    "    counter = counter + 1\n",
    "    print(f'[{counter}] Obteniendo 30 tweets de {user}. ', end = '\\n')\n",
    "    try:\n",
    "        for status in tweepy.Cursor(api.user_timeline, id = user, tweet_mode=\"extended\").items(30):\n",
    "                Predict_Data.append(status)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    pass\n",
    "print(len(Predict_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = process_data(Predict_Data)\n",
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.loc[:,\"AvgHashtag\"] = (Data.groupby('UserID')[\"HashtagCount\"].transform('sum'))/30\n",
    "Data.loc[:,\"AvgURLCount\"] = (Data.groupby('UserID')[\"HttpCount\"].transform('sum'))/30\n",
    "Data.loc[:,\"AvgMention\"] = (Data.groupby('UserID')[\"MentionCount\"].transform('sum'))/30\n",
    "Data.loc[:,\"AvgRetweet\"] = (Data.groupby('UserID')[\"RetweetCount\"].transform('sum'))/30\n",
    "Data.loc[:,\"AvgFavCount\"] = (Data.groupby('UserID')[\"TweetFavouriteCount\"].transform('sum'))/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_spam_row = Data[[\"UserID\", \"UserScreenName\", \"UserName\", \"UserCreatedAt\", \"UserDescription\", \"UserDescriptionLength\",\"UserFollowersCount\", \"UserFriendsCount\", \"UserLocation\", \"AvgHashtag\", \"AvgURLCount\", \"AvgMention\", \"AvgRetweet\", \"AvgFavCount\", \"TweetCount\"]]\n",
    "predict_data = unique_spam_row.drop_duplicates()\n",
    "predict_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "Current_Time = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d')\n",
    "predict_data.loc[:, \"CurrentDate\"]=Current_Time\n",
    "Predict_data = predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_data.loc[:,\"Reputation\"]=Predict_data[\"AvgRetweet\"]/(Predict_data[\"UserFollowersCount\"])\n",
    "Predict_data[\"Reputation\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Predict_data\n",
    "data[\"CurrentDate\"] = pd.to_datetime(data[\"CurrentDate\"])\n",
    "data[\"UserCreatedAt\"] = pd.to_datetime(data[\"UserCreatedAt\"])\n",
    "data['AgeOfAccount'] = (data['CurrentDate'] - data['UserCreatedAt'])/np.timedelta64(1, 'D')\n",
    "cols = ['AgeOfAccount']\n",
    "data[cols] = data[cols].mask(data[cols]<0)\n",
    "data.AgeOfAccount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data\n",
    "data1.loc[:, \"TweetPerDay\"] = data1[\"TweetCount\"]/data1[\"AgeOfAccount\"]\n",
    "data1[\"TweetPerDay\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[:,\"TweetPerFollower\"] = data1[\"TweetCount\"]/data1[\"UserFollowersCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove unwanted data\n",
    "data1.TweetPerFollower=data1.TweetPerFollower.round(2).fillna(0)\n",
    "data1 = data1[np.isfinite(data1['TweetPerFollower'])]\n",
    "data1[\"TweetPerFollower\"].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(data1[\"UserFriendsCount\"].item() > 0):\n",
    "    data1.loc[:,\"AgeByFollowing\"] = data1[\"AgeOfAccount\"]/data1[\"UserFriendsCount\"]\n",
    "    data1 = data1[np.isfinite(data1['AgeByFollowing'])]\n",
    "    data1[['AgeByFollowing']] = data1[['AgeByFollowing']].astype(float)\n",
    "else:\n",
    "    data1.loc[:,\"AgeByFollowing\"] = 0\n",
    "data1[\"AgeByFollowing\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[:,'screen_name_binary'] = (data1.UserScreenName.str.contains(\"Bot|bot|b0t|B0t|BOT\", case=False)==True)\n",
    "data1['name_binary'] = (data1.UserName.str.contains(\"Bot|bot|b0t|B0t|BOT\", case=False)==True)\n",
    "data1['description_binary'] = (data1.UserDescription.str.contains(\"Bot|bot|b0t|B0t|BOT\", case=False)==True)\n",
    "data1[['screen_name_binary']] = data1[['screen_name_binary']].astype(int)\n",
    "data1[['name_binary']] = data1[['name_binary']].astype(int)\n",
    "data1[['description_binary']] = data1[['description_binary']].astype(int)\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1[['Reputation', 'AvgHashtag', 'AvgRetweet', 'UserFollowersCount','UserFriendsCount', 'AvgFavCount', 'AvgMention', 'AvgURLCount', 'TweetCount', 'AgeOfAccount', 'TweetPerDay', 'TweetPerFollower', 'AgeByFollowing', 'screen_name_binary', 'name_binary', 'description_binary']]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.3 64-bit (conda)",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "80f025734193d6872cfdb8124d074171f4e6627b2e4b90c3fe4a88a97d10e5c2"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}